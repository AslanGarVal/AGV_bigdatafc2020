{"cells":[{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, MinMaxScaler, ChiSqSelector\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.sql.types import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["try:\n  from pyspark.sql import SparkSession\nexcept:\n  import findspark\n  findspark.init()\n  from pyspark.sql import SparkSession\n\n  spark = SparkSession.builder.appName(\"COVID\") \\\n          .config(\"hive.exec.dynamic.partition\", \"true\") \\\n          .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\")\\\n          .enableHiveSupport()\\\n          .getOrCreate()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["def generaDataset(fileloc, columnas):\n  \"\"\"\n  fileloc - string que da la dirección del csv con nuestros datos\n  columnas - lista con las columnas que queremos utilizar en el dataframe\n  \n  Devuelve un dataframe a partir del csv en fileloc con las columnas requeridas\n  \"\"\"\n  df = spark.read.csv(fileloc, sep = \",\", header = True, encoding = \"UTF-8\", inferSchema = True)\n  df = dataClean(df, columnas)\n  print(\"Se generó el dataframe:\")\n  print(df.show(5))\n  print(\"con %d registros\" % df.count())\n  return df\n\ndef dataClean(df, columnas):\n  \"\"\"\n  Filtra el dataframe df  por positivos a Covid\n  \"\"\"\n  df = df.filter(df[\"RESULTADO\"] == \"Positivo SARS-CoV-2\")\n  df = df.select(columnas)\n  return df"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["#columnas a utilizar\ncolumnas = [\"SEXO\", \"OBESIDAD\", \"DIABETES\", \"EPOC\", \"ASMA\", \"CARDIOVASCULAR\", \"RENAL CRONICA\", \"TABAQUISMO\", \"TIPO PACIENTE\", \"EDAD\"]\nfile = \"/FileStore/tables/casos_asociados_a_covid_19-4388c.csv\"\n\ndf = generaDataset(file, columnas)\ntrain, test = df.randomSplit([0.70, 0.30])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Se generó el dataframe:\n+------+--------+--------+----+----+--------------+-------------+----------+-------------+----+\n  SEXO|OBESIDAD|DIABETES|EPOC|ASMA|CARDIOVASCULAR|RENAL CRONICA|TABAQUISMO|TIPO PACIENTE|EDAD|\n+------+--------+--------+----+----+--------------+-------------+----------+-------------+----+\n MUJER|      SI|      SI|  NO|  NO|            NO|           NO|        NO|  AMBULATORIO|  61|\nHOMBRE|      NO|      NO|  NO|  NO|            NO|           NO|        NO|  AMBULATORIO|  54|\nHOMBRE|      NO|      NO|  NO|  NO|            NO|           NO|        NO|  AMBULATORIO|  30|\n MUJER|      NO|      NO|  NO|  NO|            NO|           NO|        NO|HOSPITALIZADO|  51|\n MUJER|      NO|      NO|  NO|  SI|            NO|           NO|        NO|  AMBULATORIO|  32|\n+------+--------+--------+----+----+--------------+-------------+----------+-------------+----+\nonly showing top 5 rows\n\nNone\ncon 6296 registros\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["df.groupBy(\"TIPO PACIENTE\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+-----+\nTIPO PACIENTE|count|\n+-------------+-----+\n  AMBULATORIO| 4030|\nHOSPITALIZADO| 2266|\n+-------------+-----+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["def pruebaChiSquare(data, numCols, catCols, target):\n  \"\"\"\n  Realiza la prueba de chi^2 en el dataset provisto después de un poco de procesamiento \n  Regresa el dataset procesado y con sólo con las variables relevantes, a partir de la prueba de chi^2\n  \n  data -- dataframe a utilizar\n  numCols -- lista con las features numéricas del dataset\n  catCols -- lista con las features categóricas del dataset\n  target -- string con el nombre la variable objetivo a utilizar para la prueba\n  \"\"\"\n  stages = []\n  for categoricalCol in catCols:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + \"index\")\n    stages += [stringIndexer]\n  labelStringIndexer = StringIndexer(inputCol = target, outputCol = \"label\")\n  stages += [labelStringIndexer]\n  assemblerInputs = [c + \"index\" for c in catCols] + numCols\n  assembler = VectorAssembler(inputCols = assemblerInputs, outputs = \"features\")\n  css = ChiSqSelector(features = 'features', outputCol = \"salidaf\", labelCol = 'label', fpr = 0.05)\n  stages += [assembler, css]\n  pipe = Pipeline().setStages(stages)\n  result = pipe.fit(data).transform(data)\n  return result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def entrenamiento(data, catCols, numCols, target):\n  \"\"\"\n  Crea un pipeline donde las variables categóricas se procesan usando one-hot-encoding\n  pasa la data transformada al modelo logístico y regresa el modelo ajustado.\n  \n  data -- el dataframe a utilizar\n  catCols -- lista con las columnas categóricas de las features a usar\n  numCols -- lista con las columnas numéricas de las features\n  target -- la variable que deseamos modelar con la regresión logística\n  \"\"\"\n  stages = []\n  for categoricalCol in catCols:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + \"index\")\n    stages += [stringIndexer]\n    ohe = OneHotEncoderEstimator(inputCols = [stringIndexer.getOutputCol()], outputCols = [categoricalCol + \"ohe\"])\n    stages += [ohe]\n  label_stringIdx = StringIndexer(inputCol = target, outputCol = \"label\")\n  stages += [label_stringIdx]\n  assemblerInputs = [c+\"ohe\" for c in catCols] + numCols\n  assembler = VectorAssembler(inputCols = assemblerInputs, outputCol = \"featuresVec\")\n  minmax = MinMaxScaler(inputCol = \"featuresVec\", outputCol = \"features\")\n  lr = LogisticRegression(labelCol = \"label\", featuresCol = \"features\", maxIter = 10)\n  stages += [assembler, minmax, lr]\n  pipe = Pipeline().setStages(stages)\n  model = pipe.fit(data)\n  \n  print(\"Coeficientes: \" + str(model.stages[-1].coefficientMatrix))\n  print(\"Intercepto: \" + str(model.stages[-1].interceptVector))\n  return model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["def metricas(prediccion):\n  \"\"\"\n  Regresa el accuracy y la curva ROC del modelo \n  \n  prediccion -- dataframe con el dataset de test\n  \"\"\"\n  score = MulticlassClassificationEvaluator(\n  predictionCol = \"prediction\",\n  labelCol = \"label\",\n  metricName = \"accuracy\")\n  \n  evaluator = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = \"label\")\n  print(\"El accuracy del modelo es:\")\n  print(score.evaluate(prediccion))\n  print(\"La curva ROC del modelo es:\")\n  print(evaluator.evaluate(prediccion))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["numericalColumns = columnas[-1:]\ntarget = columnas[-2]\ncategoricalColumns = columnas[:-2]\nmodelo = entrenamiento(train, categoricalColumns, numericalColumns, target)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Exception ignored in: &lt;function JavaWrapper.__del__ at 0x7f9c1fc1dc80&gt;\nTraceback (most recent call last):\n  File &#34;/databricks/spark/python/pyspark/ml/wrapper.py&#34;, line 40, in __del__\n    if SparkContext._active_spark_context and self._java_obj is not None:\nAttributeError: &#39;VectorAssembler&#39; object has no attribute &#39;_java_obj&#39;\nCoeficientes: DenseMatrix([[ 0.53528989, -0.30821661,  0.2012714 , -0.42596433,  0.38316161,\n              -0.49689643,  0.31850112, -0.07320358, -0.22327416, -0.32468339,\n              -0.09725334, -0.78408543,  0.32849561, -0.21189713,  0.06657103,\n               4.04393641]])\nIntercepto: [-0.5794737210407417]\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["prediccion = modelo.transform(train)\nmetricas(prediccion)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">El accuracy del modelo es:\n0.7149372862029647\nLa curva ROC del modelo es:\n0.7510262424370612\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["def structDataframe(data):\n  \"\"\"\n  Dada una lista con entradas de datos, regresa un dataframe con dichos datos y el esquema de abajo\n  data -- lista con listas, cada lista tiene datos de EDAD, SEXO, etc...\n  \"\"\"\n  schema = StructType([\n    StructField(\"EDAD\", IntegerType(), True),\n    StructField(\"SEXO\", StringType(), True),\n    StructField(\"OBESIDAD\", StringType(), True),\n    StructField(\"DIABETES\", StringType(), True),\n    StructField(\"EPOC\", StringType(), True),\n    StructField(\"ASMA\", StringType(), True),\n    StructField(\"CARDIOVASCULAR\", StringType(), True),\n    StructField(\"TABAQUISMO\", StringType(), True),\n    StructField(\"RENAL CRONICA\", StringType(), True)\n  ])\n  \n  df = spark.createDataFrame(data, schema)\n  return df"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["data = [[25, \"HOMBRE\", \"NO\", \"SI\", \"SI\", \"NO\", \"NO\", \"NO\", \"SI\"], [70, \"MUJER\", \"NO\", \"SI\", \"NO\", \"NO\", \"NO\", \"NO\", \"NO\"]]\ndf2 = structDataframe(data)\nresult = modelo.transform(df2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"CovidLogistico","notebookId":1452864592342103},"nbformat":4,"nbformat_minor":0}
